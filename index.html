<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation">
   <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta property="og:title" content="Active Vision Might Be All You Need"/>
  <meta property="og:description" content="Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Active Vision Might Be All You Need">
  <meta name="twitter:description" content="Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Robotic Manipulation, Active Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Active Vision Might Be All You Need</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body onload="updateInteractive();">

<section class="hero">
  <div class="hero-body">
    <div class="container is-fullhd">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="">Ian Chuang</a><sup>*</sup><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="">Andrew Lee</a><sup>*</sup><sup>2</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="">Dechen Gao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="">Iman Soltani</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Berkeley,</span>
            <span class="author-block"><sup>2</sup>University of California, Davis</span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a target="_blank" href="Active_Vision_Might_Be_All_You_Need.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

            <!-- Arxiv Link. -->
            <span class="link-block">
              <a target="_blank" href="https://arxiv.org/abs/"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file"></i>
                </span>
                <span>ArXiv</span>
              </a>
            </span>

            <!-- Video Link. -->
            <span class="link-block">
              <a target="_blank" href="https://youtu.be/0qQJ4Dpt_KU"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>

            <!-- Code Link. -->
            <span class="link-block">
              <a target="_blank" href="https://github.com/soltanilara"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-fullhd">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-vcentered  is-centered">
          <video id="teaser" autoplay muted loop height="60%" width="60%">
            <source src="media/videos/teaser.mp4"
                    type="video/mp4">
          </video>
          </br>
        </div>
        <br>
        <h2 class="subtitle has-text-centered">
        <span class="dperact">We introduce <b>AV-ALOHA</b>, a bimanual robot system with <b>7-DoF active vision (AV)</b>. In this system, a VR headset provides a live feed from the AV camera to the user. The movement of the VR headset controls the AV arm.
        </h2>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                    type="video/mp4">
          </video>
          <video poster="" autoplay muted loop height="100%">
            <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop height="100%">
            <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                    type="video/mp4">
          </video>
          <video poster="" autoplay muted loop height="100%">
            <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<h2 class="subtitle has-text-centered">
</br>
AV-ALOHA, both in simulation and in real-world, provides an immersive teleoperation experience with bimanual first-person control, <br> enabling the operator to dynamically explore and search the scene and simultaneously interact with the environment.
</h2>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning has demonstrated significant potential in performing high-precision manipulation tasks using visual feedback from cameras. However, it is common practice in imitation learning for cameras to be fixed in place, resulting in issues like occlusion and limited field of view. Furthermore, cameras are often placed in broad, general locations, without an effective viewpoint specific to the robot's task. In this work, we investigate the utility of active vision (AV) for imitation learning and manipulation, in which, in addition to the manipulation policy, the robot learns an AV policy from human demonstrations to dynamically change the robot's camera viewpoint to obtain better information about its environment and the given task. We introduce AV-ALOHA, a new bimanual teleoperation robot system with AV, an extension of the ALOHA 2 robot system, incorporating an additional 7-DoF robot arm that only carries a stereo camera and is solely tasked with finding the best viewpoint. This camera streams stereo video to an operator wearing a virtual reality (VR) headset, allowing the operator to control the camera pose using head and body movements. The system provides an immersive teleoperation experience, with bimanual first-person control, enabling the operator to dynamically explore and search the scene and simultaneously interact with the environment. We conduct imitation learning experiments of our system both in real-world and in simulation, across a variety of tasks that emphasize viewpoint planning. Our results demonstrate the effectiveness of human-guided AV for imitation learning, showing significant improvements over fixed cameras in tasks with limited visibility.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>

  <!-- Paper video. -->
  <br>
  <br>

  <div class="container is-max-widescreen">

    <div class="rows">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <iframe src="https://www.youtube.com/embed/0qQJ4Dpt_KU"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>
  </div>

</section>

<section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">


    <!-- Animation. -->
    <div class="rows is-centered ">
      <div class="row is-full-width">
        <h2 class="title is-3"><span class="dperact">Imitation Learning</span></h2>

        <!-- Interpolating. -->
        <div class="content has-text-justified">
        <!-- <br> -->
        </div>
        <img src="static/images/ActiveVisionSystemFigure.png" class="interpolation-image" />
        </br>
        </br>
          <p class="content has-text-justified">
            The AV-ALOHA system enables intuitive data collection using a VR headset for AV and either VR controllers or leader arms for manipulation. This helps capture full body and head movements to teleoperate both our real and simulation system that record video from six different cameras and provide training data for our AV imitation learning policies. 
          </p>
        </br>
        </br>

        <!--/ Re-rendering. -->

        <h2 class="title is-3">Data Collection</h2>

        <section class="hero is-light is-small">
          <div class="hero-body is-max-widescreen">
            <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <video poster="" autoplay muted loop height="100%">
                    <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                            type="video/mp4">
                  </video>
                  <video poster="" autoplay muted loop height="100%">
                    <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                            type="video/mp4">
                  </video>
                  <video poster="" autoplay muted loop height="100%">
                    <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                            type="video/mp4">
                  </video>
                </div>
                <div class="item">
                <video poster="" autoplay muted loop height="100%">
                  <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                          type="video/mp4">
                </video>
                </div>
              </div>
            </div>
          </div>  
        </section>
      </br>
    </br>

        <h2 class="title is-3">Autonomous Rollouts</h2>
        
        <section class="hero is-light is-small">
          <div class="hero-body is-max-widescreen">
            <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <video poster="" autoplay muted loop height="100%">
                    <source src="static/videos/sim_hook_package/eval_episode_0.mp4"
                            type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay muted loop height="100%">
                    <source src="media/videos/close-top-drawer-dist.mp4"
                            type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
          </div>  
        </section>
        
    

<section class="section" id="BibTeX">
  <div class="container is-max-widescreen content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chuang2024activevision,
      title={Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation},
      author={Chuang, Ian and Lee, Andrew and Gao, Dechen and Soltani, Iman, Soltani},
      journal={arXiv preprint arXiv:},
      year={2024}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
